{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb"
      },
      "source": [
        "# **Homework 12 - Reinforcement Learning**\n",
        "\n",
        "If you have any problem, e-mail us at mlta-2023-spring@googlegroups.com\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk"
      },
      "source": [
        "## Preliminary work\n",
        "\n",
        "First, we need to install all necessary packages.\n",
        "One of them, gym, builded by OpenAI, is a toolkit for developing Reinforcement Learning algorithm. Other packages are for visualization in colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2bScpnkVbv",
        "outputId": "3664b9aa-2a3e-4bba-a268-2c9871efc7ab"
      },
      "outputs": [],
      "source": [
        "# !apt update\n",
        "# !apt install python-opengl xvfb -y\n",
        "# !pip install -q swig\n",
        "# !pip install box2d==2.3.2 gym[box2d]==0.25.2 box2d-py pyvirtualdisplay tqdm numpy==1.22.4 \n",
        "# !pip install box2d==2.3.2 box2d-kengz\n",
        "# !pip freeze > requirements.txt\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks"
      },
      "source": [
        "\n",
        "Next, set up virtual display，and import all necessaary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nl2nREINDLiw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from IPython import display\n",
        "import imageio\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import deque, namedtuple\n",
        "from einops import repeat\n",
        "from torch.distributions import MultivariateNormal, Normal\n",
        "from torch.nn.utils import clip_grad_norm_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CaEJ8BUCpN9P"
      },
      "source": [
        "# Warning ! Do not revise random seed !!!\n",
        "# Your submission on JudgeBoi will not reproduce your result !!!\n",
        "Make your HW result to be reproducible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "outputs": [],
      "source": [
        "seed = 2023 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC"
      },
      "source": [
        "Last, call gym and build an [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N_4-xJcbBt09"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "env = gym.make('LunarLander-v2')\n",
        "fix(env, seed) # fix the environment Do not revise this !!!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NrkVvTrvWZ5H"
      },
      "source": [
        "## What Lunar Lander？\n",
        "\n",
        "“LunarLander-v2”is to simulate the situation when the craft lands on the surface of the moon.\n",
        "\n",
        "This task is to enable the craft to land \"safely\" at the pad between the two yellow flags.\n",
        "> Landing pad is always at coordinates (0,0).\n",
        "> Coordinates are the first two numbers in state vector.\n",
        "\n",
        "![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
        "\n",
        "\"LunarLander-v2\" actually includes \"Agent\" and \"Environment\". \n",
        "\n",
        "In this homework, we will utilize the function `step()` to control the action of \"Agent\". \n",
        "\n",
        "Then `step()` will return the observation/state and reward given by the \"Environment\"."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbp82sljvAt"
      },
      "source": [
        "### Observation / State\n",
        "\n",
        "First, we can take a look at what an Observation / State looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXZra3N9R5T",
        "outputId": "a36b4dd1-fc58-420d-d5d1-84db2ab3fe28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Box(-inf, inf, (8,), float32)\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdfoThbAQ49"
      },
      "source": [
        "\n",
        "`Box(8,)`means that observation is an 8-dim vector\n",
        "### Action\n",
        "\n",
        "Actions can be taken by looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1k4dIrBAaKi",
        "outputId": "1a7cecb7-385f-450c-c11c-07c32ccd5a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete(4)\n"
          ]
        }
      ],
      "source": [
        "print(env.action_space)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dejXT6PHBrPn"
      },
      "source": [
        "`Discrete(4)` implies that there are four kinds of actions can be taken by agent.\n",
        "- 0 implies the agent will not take any actions\n",
        "- 2 implies the agent will accelerate downward\n",
        "- 1, 3 implies the agent will accelerate left and right\n",
        "\n",
        "Next, we will try to make the agent interact with the environment. \n",
        "Before taking any actions, we recommend to call `reset()` function to reset the environment. Also, this function will return the initial state of the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4OmrmZgnWA",
        "outputId": "ecd0b477-c7d3-4a34-ddb8-0eadd5cb9147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.00215788  1.4030764   0.21855156 -0.3486134  -0.00249362 -0.0495052\n",
            "  0.          0.        ]\n"
          ]
        }
      ],
      "source": [
        "initial_state = env.reset()\n",
        "print(initial_state)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uBx0mEqqgxJ9"
      },
      "source": [
        "Then, we try to get a random action from the agent's action space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxkOEXRKgizt",
        "outputId": "9bd00d32-f7bd-4b76-eeea-7bdd935597b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "random_action = env.action_space.sample()\n",
        "print(random_action)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mns-bO01g0-J"
      },
      "source": [
        "More, we can utilize `step()` to make agent act according to the randomly-selected `random_action`.\n",
        "The `step()` function will return four values:\n",
        "- observation / state\n",
        "- reward\n",
        "- done (True/ False)\n",
        "- Other information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E_WViSxGgIk9"
      },
      "outputs": [],
      "source": [
        "observation, reward, done, info = env.step(random_action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7r126kuCNp",
        "outputId": "cf191223-aabf-48b7-8393-114f0df9dcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(done)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdS8vOihxhc"
      },
      "source": [
        "### Reward\n",
        "\n",
        "\n",
        "> Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQNs77hi0_7",
        "outputId": "9a260648-5c49-4b76-c94f-985a2ce65cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.58213605344352\n"
          ]
        }
      ],
      "source": [
        "print(reward)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhqp6D-XgHpe"
      },
      "source": [
        "### Random Agent\n",
        "In the end, before we start training, we can see whether a random agent can successfully land the moon or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "Y3G0bxoccelv",
        "outputId": "442108bc-db1c-4033-9cee-c2b6c084be52"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "env.reset()\n",
        "\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _ = env.step(action)\n",
        "\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Noisy Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from abc import ABC\n",
        "\n",
        "class AbstractNoisyLayer(nn.Module, ABC):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_features: int,\n",
        "            output_features: int,\n",
        "            sigma: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sigma = sigma\n",
        "        self.input_features = input_features\n",
        "        self.output_features = output_features\n",
        "\n",
        "        self.mu_bias = nn.Parameter(torch.FloatTensor(output_features))\n",
        "        self.sigma_bias = nn.Parameter(torch.FloatTensor(output_features))\n",
        "        self.mu_weight = nn.Parameter(torch.FloatTensor(output_features, input_features))\n",
        "        self.sigma_weight = nn.Parameter(torch.FloatTensor(output_features, input_features))\n",
        "\n",
        "        self.register_buffer('epsilon_input', torch.FloatTensor(input_features))\n",
        "        self.register_buffer('epsilon_output', torch.FloatTensor(output_features))\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            x: torch.Tensor,\n",
        "            sample_noise: bool = True\n",
        "    ) -> torch.Tensor:\n",
        "        if not self.training:\n",
        "            return nn.functional.linear(x, weight=self.mu_weight, bias=self.mu_bias)\n",
        "\n",
        "        if sample_noise:\n",
        "            self.sample_noise()\n",
        "\n",
        "        return nn.functional.linear(x, weight=self.weight, bias=self.bias)\n",
        "\n",
        "    @property\n",
        "    def weight(self) -> torch.Tensor:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def bias(self) -> torch.Tensor:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def sample_noise(self) -> None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def parameter_initialization(self) -> None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_noise_tensor(self, features: int) -> torch.Tensor:\n",
        "        noise = torch.FloatTensor(features).uniform_(-self.bound, self.bound).to(self.mu_bias.device)\n",
        "        return torch.sign(noise) * torch.sqrt(torch.abs(noise))\n",
        "\n",
        "\n",
        "class IndependentNoisyLayer(AbstractNoisyLayer):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_features: int,\n",
        "            output_features: int,\n",
        "            sigma: float = 0.017,\n",
        "    ):\n",
        "        super(AbstractNoisyLayer).__init__(\n",
        "            input_features=input_features,\n",
        "            output_features=output_features,\n",
        "            sigma=sigma\n",
        "        )\n",
        "\n",
        "        self.bound = (3 / input_features) ** 0.5\n",
        "        self.parameter_initialization()\n",
        "        self.sample_noise()\n",
        "\n",
        "    @property\n",
        "    def weight(self) -> torch.Tensor:\n",
        "        return self.sigma_weight * self.epsilon_weight + self.mu_weight\n",
        "\n",
        "    @property\n",
        "    def bias(self) -> torch.Tensor:\n",
        "        return self.sigma_bias * self.epsilon_bias + self.mu_bias\n",
        "\n",
        "    def sample_noise(self) -> None:\n",
        "        self.epsilon_bias = self.get_noise_tensor((self.output_features,))\n",
        "        self.epsilon_weight = self.get_noise_tensor((self.output_features, self.input_features))\n",
        "\n",
        "    def parameter_initialization(self) -> None:\n",
        "        self.sigma_bias.data.fill_(self.sigma)\n",
        "        self.sigma_weight.data.fill_(self.sigma)\n",
        "        self.mu_bias.data.uniform_(-self.bound, self.bound)\n",
        "        self.mu_weight.data.uniform_(-self.bound, self.bound)\n",
        "\n",
        "\n",
        "class FactorisedNoisyLayer(AbstractNoisyLayer):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_features: int,\n",
        "            output_features: int,\n",
        "            sigma: float = 0.5,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            input_features=input_features,\n",
        "            output_features=output_features,\n",
        "            sigma=sigma\n",
        "        )\n",
        "\n",
        "        # self.input_features = input_features\n",
        "        # self.output_features = output_features\n",
        "        # self.sigma = sigma\n",
        "\n",
        "        self.bound = input_features**(-0.5)\n",
        "        self.parameter_initialization()\n",
        "        self.sample_noise()\n",
        "\n",
        "    @property\n",
        "    def weight(self) -> torch.Tensor:\n",
        "        return self.sigma_weight * torch.ger(self.epsilon_output, self.epsilon_input) + self.mu_weight\n",
        "\n",
        "    @property\n",
        "    def bias(self) -> torch.Tensor:\n",
        "        return self.sigma_bias * self.epsilon_output + self.mu_bias\n",
        "\n",
        "    def sample_noise(self) -> None:\n",
        "        self.epsilon_input = self.get_noise_tensor(self.input_features)\n",
        "        self.epsilon_output = self.get_noise_tensor(self.output_features)\n",
        "\n",
        "    def parameter_initialization(self) -> None:\n",
        "        self.mu_bias.data.uniform_(-self.bound, self.bound)\n",
        "        self.sigma_bias.data.fill_(self.sigma * self.bound)\n",
        "        self.mu_weight.data.uniform_(-self.bound, self.bound)\n",
        "        self.sigma_weight.data.fill_(self.sigma * self.bound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "BUFFER_SIZE = 5000000000  # replay buffer size\n",
        "BATCH_SIZE = 32         # minibatch size\n",
        "EPOCH = 4000\n",
        "GAMMA = 0.99            # discount factor\n",
        "TAU = 1e-3              # for soft update of target parameters\n",
        "LR = 1e-3               # learning rate \n",
        "UPDATE_EVERY = 10        # how often to update the network\n",
        "DUELING = True\n",
        "PARAM_NOISE = True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F5paWqo7tWL2"
      },
      "source": [
        "## Policy Gradient\n",
        "Now, we can build a simple policy network. The network will return one of action in the action space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "J8tdmeD-tZew"
      },
      "outputs": [],
      "source": [
        "# class PolicyGradientNetwork(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.fc1 = nn.Linear(8, 16)\n",
        "#         self.fc2 = nn.Linear(16, 16)\n",
        "#         self.fc3 = nn.Linear(16, 4)\n",
        "#     def forward(self, state):\n",
        "#         hid = torch.tanh(self.fc1(state))\n",
        "#         hid = torch.tanh(hid)\n",
        "#         return F.softmax(self.fc3(hid), dim=-1)\n",
        "    \n",
        "class DQN(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model\"\"\"\n",
        "    def __init__(self, b_dueling=False, b_param_noise=False, sigma=0.5):\n",
        "        super().__init__()\n",
        "        self.b_dueling = b_dueling\n",
        "        self.b_param_noise = b_param_noise\n",
        "        self.input_dim = 8\n",
        "        self.latent_dim = 16\n",
        "        self.output_dim = 4\n",
        "        self.pre_net = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.latent_dim,self.latent_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.noisy_pre_net = nn.Sequential(\n",
        "            FactorisedNoisyLayer(self.input_dim, self.latent_dim, sigma=sigma),\n",
        "            nn.ReLU(),\n",
        "            FactorisedNoisyLayer(self.latent_dim, self.latent_dim, sigma=sigma),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.netA = nn.Sequential(\n",
        "            nn.Linear(self.latent_dim, self.output_dim),\n",
        "        )\n",
        "        self.netV = nn.Sequential(\n",
        "            nn.Linear(self.latent_dim, int(self.latent_dim/2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(int(self.latent_dim/2),1),\n",
        "            # nn.Linear(self.latent_dim, 1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.noisy_netA = nn.Sequential(\n",
        "            FactorisedNoisyLayer(self.latent_dim, self.output_dim, sigma=sigma),\n",
        "        )\n",
        "        self.noisy_netV = nn.Sequential(\n",
        "            FactorisedNoisyLayer(self.latent_dim, int(self.latent_dim/2), sigma=sigma),\n",
        "            nn.ReLU(),\n",
        "            FactorisedNoisyLayer(int(self.latent_dim/2), 1, sigma=sigma),\n",
        "            # FactorisedNoisyLayer(self.latent_dim, 1, sigma=sigma),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, state):\n",
        "        x = state\n",
        "        if self.b_param_noise:\n",
        "            x = self.noisy_pre_net(x)\n",
        "            outA = self.noisy_netA(x)\n",
        "            outA = outA.reshape(-1,self.output_dim)\n",
        "            outV = 0\n",
        "            if self.b_dueling:\n",
        "                outV = self.noisy_netV(x)\n",
        "                return (outA - torch.mean(outA)) + outV, outA, outV\n",
        "            else:\n",
        "                return outA, outA, outV\n",
        "        else:\n",
        "            x = self.pre_net(x)\n",
        "            outA = self.netA(x)\n",
        "            outA = outA.reshape(-1,self.output_dim)\n",
        "            outV = 0\n",
        "            if self.b_dueling:\n",
        "                outV = self.netV(x)\n",
        "                return (outA - torch.mean(outA)) + outV, outA, outV\n",
        "            else:\n",
        "                return outA, outA, outV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbqJrhIFTC3"
      },
      "source": [
        "Then, we need to build a simple agent. The agent will acts according to the output of the policy network above. There are a few things can be done by agent:\n",
        "- `learn()`：update the policy network from log probabilities and rewards.\n",
        "- `sample()`：After receiving observation from the environment, utilize policy network to tell which action to take. The return values of this function includes action and log probabilities. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "zZo-IxJx286z"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "# class PolicyGradientAgent():\n",
        "#     def __init__(self, network):\n",
        "#         self.network = network\n",
        "#         self.optimizer = optim.SGD(self.network.parameters(), lr=0.002)\n",
        "        \n",
        "#     def forward(self, state):\n",
        "#         return self.network(state)\n",
        "#     def learn(self, log_probs, rewards):\n",
        "#         loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n",
        "\n",
        "#         self.optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         self.optimizer.step()\n",
        "        \n",
        "#     def sample(self, state):\n",
        "#         action_prob = self.network(torch.FloatTensor(state))\n",
        "#         action_dist = Categorical(action_prob)\n",
        "#         action = action_dist.sample()\n",
        "#         log_prob = action_dist.log_prob(action)\n",
        "#         return action.item(), log_prob\n",
        "\n",
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "    def __init__(self, state_size, action_size):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = DQN(DUELING).to(device)\n",
        "        self.qnetwork_target = DQN(DUELING).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(BUFFER_SIZE)\n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0\n",
        "    \n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        # Obtain random minibatch of tuples from D\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        ## Compute and minimize the loss\n",
        "        ### Extract next maximum estimated value from target network\n",
        "        q_targets_next, val_A, val_V = self.qnetwork_target(next_states)\n",
        "        q_targets_next = q_targets_next.detach().max(1)[0].unsqueeze(1)\n",
        "        ### Calculate target value from bellman equation\n",
        "        q_targets = rewards + gamma * q_targets_next * (1 - dones)\n",
        "        ### Calculate expected value from local network\n",
        "        q_expected, val_A, val_V = self.qnetwork_local(states)\n",
        "        q_expected = q_expected.gather(1, actions)\n",
        "        \n",
        "        ### Loss calculation (we used Mean squared error)\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                    \n",
        "    \n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.push(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > BATCH_SIZE:\n",
        "                experiences = self.memory.sample(BATCH_SIZE)\n",
        "                self.learn(experiences, GAMMA)\n",
        "\n",
        "    def sample_action(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        # Double DQN\n",
        "        with torch.no_grad():\n",
        "            action_values, val_A, val_V = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        if PARAM_NOISE:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            # Epsilon-greedy action selection\n",
        "            if random.random() > eps: # choose action with best value\n",
        "                return np.argmax(action_values.cpu().data.numpy())\n",
        "            else: # random exploration\n",
        "                return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter \n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
        "\n",
        "    def save(self, MODEL_PATH): # You should not revise this\n",
        "        Agent_Dict = {\n",
        "            \"network\" : self.qnetwork_local.state_dict(),\n",
        "            \"optimizer\" : self.optimizer.state_dict()\n",
        "        }\n",
        "        torch.save(Agent_Dict, MODEL_PATH)\n",
        "\n",
        "    def load(self, PATH): # You should not revise this\n",
        "        checkpoint = torch.load(PATH)\n",
        "        self.qnetwork_local.load_state_dict(checkpoint[\"network\"])\n",
        "        #如果要儲存過程或是中斷訓練後想繼續可以用喔 ^_^\n",
        "        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, buffer_size=5000):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "        Params\n",
        "        ======\n",
        "            buffer_size (int): maximum size of buffer\n",
        "        \"\"\"\n",
        "        self.memory = deque([], maxlen=buffer_size)\n",
        "    \n",
        "    class experience():\n",
        "        def __init__(self, state, action, reward, next_state, done):\n",
        "            self.state = state\n",
        "            self.action = action\n",
        "            self.reward = reward\n",
        "            self.next_state = next_state\n",
        "            self.done = done\n",
        "\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self, BATCH):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, BATCH)\n",
        "        \n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ehPlnTKyRZf9"
      },
      "source": [
        "Lastly, build a network and agent to start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GfJIvML-RYjL"
      },
      "outputs": [],
      "source": [
        "# network = PolicyGradientNetwork()\n",
        "# agent = PolicyGradientAgent(network)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ouv23glgf5Qt"
      },
      "source": [
        "## Training Agent\n",
        "\n",
        "Now let's start to train our agent.\n",
        "Through taking all the interactions between agent and environment as training data, the policy network can learn from all these attempts,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(agent, action_list_path):\n",
        "    fix(env, seed)\n",
        "    agent.qnetwork_local.eval()  # set the network into evaluation mode\n",
        "    agent.qnetwork_target.eval()  # set the network into evaluation mode\n",
        "    NUM_OF_TEST = 5 # Do not revise this !!!\n",
        "    test_total_reward = []\n",
        "    action_list = []\n",
        "    for i in range(NUM_OF_TEST):\n",
        "        actions = []\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = agent.sample_action(state)\n",
        "            actions.append(action)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "        test_total_reward.append(total_reward)\n",
        "        action_list.append(actions) # save the result of testing \n",
        "    #print(\"  test-total-reward: \", test_total_reward)\n",
        "    np.save(action_list_path, np.array(action_list)) \n",
        "    return np.mean(test_total_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_total_rewards, avg_final_rewards = [], []\n",
        "total_rewards, final_rewards = [], []\n",
        "\n",
        "def train(agent, n_episode=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995, work_dir=\"./\", save_every=200):\n",
        "    \"\"\"Deep Q-Learning\n",
        "    Params\n",
        "    ======\n",
        "        n_epoch (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection (similar to 'T' in SA)\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "    \"\"\"\n",
        "    ckpt_dir = \"./{}/models/\".format(work_dir)\n",
        "    fig_dir = \"./{}/figs/\".format(work_dir)\n",
        "    actions_dir = \"./{}/actions/\".format(work_dir)\n",
        "    best_dir = \"./{}/best/\".format(work_dir)\n",
        "    !mkdir -p \"{ckpt_dir}\" \"{fig_dir}\" \"{best_dir}\" \"{actions_dir}\"\n",
        "\n",
        "    total_rewards_window = deque(maxlen=1000)  # last 100 scores\n",
        "    best_reward = -9999\n",
        "    best_score = -9999 # tested reward\n",
        "    eps = eps_start                    # initialize epsilon\n",
        "    for i_episode in range(1, n_episode+1):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        final_reward = -1\n",
        "        img_list = []\n",
        "        action_list = []\n",
        "        step_count = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.sample_action(state, eps)\n",
        "            action_list.append(action)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            if i_episode % save_every == 0 or (i_episode%10==0 and i_episode<save_every) or i_episode==1:\n",
        "                img_list.append(Image.fromarray(env.render(mode='rgb_array'), 'RGB'))\n",
        "            if done:\n",
        "                step_count = t\n",
        "                final_reward = reward\n",
        "                final_rewards.append(final_reward)\n",
        "                break \n",
        "            if t == max_t-1:\n",
        "                step_count = t\n",
        "                total_reward += -100\n",
        "                final_reward = -100+reward\n",
        "                final_rewards.append(final_reward)\n",
        "                break \n",
        "        total_rewards_window.append(total_reward)              # save most recent score\n",
        "        total_rewards.append(total_reward)              # save most recent score\n",
        "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
        "\n",
        "        if i_episode % 100 == 0 or i_episode < 10:\n",
        "            print('\\rEpisode {}\\tAction length: {}, Total reward: {:.2f}, Average reward: {:.2f}, Final reward: {:.2f}'.format(i_episode, step_count, total_reward, np.mean(total_rewards_window), final_reward))\n",
        "        else: print(\".\", end=\"\")\n",
        "        if i_episode % save_every == 0 or i_episode==1:\n",
        "            chechpoint_pth = ckpt_dir+ f\"Agent_Dict-{i_episode}.ckpt\"\n",
        "            #print(f\"\\rsave model as {chechpoint_pth}.\")\n",
        "            chechpoint_pth = ckpt_dir+ f\"Agent_Dict-{i_episode}.ckpt\"\n",
        "            agent.save(chechpoint_pth)\n",
        "            np.save(ckpt_dir+f\"Action_List-{i_episode}.npy\" ,np.array(action_list)) \n",
        "            gif_pth = fig_dir + f\"layout-{i_episode}.gif\"\n",
        "            imageio.mimsave(gif_pth, img_list, 'GIF', duration=0.002)\n",
        "            img_list[0].save(gif_pth, save_all=True, append_images=img_list)\n",
        "            # test\n",
        "            action_list_path = actions_dir+f\"Action_List-{i_episode}.npy\"\n",
        "            test(agent, action_list_path)\n",
        "        \n",
        "        if total_reward >= best_reward and final_reward == 100:\n",
        "            print('\\rEpisode {}\\tAction length: {}, Total reward: {:.2f}, Average reward: {:.2f}, Final reward: {:.2f} <-- good'.format(i_episode, step_count, total_reward, np.mean(total_rewards_window), final_reward))\n",
        "            # test\n",
        "            action_list_path = actions_dir+f\"Action_List-{i_episode}.npy\"\n",
        "            test_reward = test(agent, action_list_path)\n",
        "            if test_reward > best_reward:\n",
        "                best_reward = test_reward\n",
        "                !rm -f \"{best_dir}*.ckpt\"\n",
        "                agent.save(best_dir+\"Agent_Dict.ckpt\")\n",
        "                best_i_txt = best_dir+\"best-i.txt\"\n",
        "                !echo \"{i_episode}\" best_reward=\"{best_reward}\" > \"{best_i_txt}\"\n",
        "                np.save(best_dir+\"Action_List.npy\" ,np.array(action_list))\n",
        "                print('\\rEpisode {}\\t Avg test reward: {:.2f} <-- best'.format(i_episode, test_reward))\n",
        "                cp_cmd = f\"cp {action_list_path} {best_dir}Action_List-test.npy\"\n",
        "                os.system(cp_cmd)\n",
        "        elif final_reward == 100:\n",
        "            print('\\rEpisode {}\\tAction length: {}, Total reward: {:.2f}, Average reward: {:.2f}, Final reward: {:.2f} <-- success'.format(i_episode, step_count, total_reward, np.mean(total_rewards_window), final_reward))\n",
        "\n",
        "        # 紀錄訓練過程 \n",
        "        avg_total_reward, avg_final_reward = 0, 0\n",
        "        avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "        avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "        avg_total_rewards.append(avg_total_reward)\n",
        "        avg_final_rewards.append(avg_final_reward)\n",
        "    print((f\"avgTotal: {avg_total_reward: 4.1f}, avgFinalReward: {avg_final_reward: 4.1f}, bestReward: {best_reward}\"))\n",
        "\n",
        "    return total_rewards, final_rewards, best_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a75e87122a4c4b2fa75a69b27b0f9111",
            "ff52d7994d7848429da4dc9078d2f228",
            "194b9ffbe5c8431ba02221e5f8f1e315",
            "d961617cc2924a70ae866bf25c1643bb",
            "66b62bd445394f90914856c4e6ffad8a",
            "bf39b080df3c4a9c9136740f657b0f79",
            "ad74a83a0e534484a27a1ff7b981c62a",
            "a86cc078ee82412393be06fbb41dc603",
            "6af646edfbed423a893eb4ff5a80dc65",
            "5805cbaeef104932bbc2886796b99a5c",
            "76be8412fdd94bb99c9b071764057b9b"
          ]
        },
        "id": "vg5rxBBaf38_",
        "outputId": "732e2ed7-8304-4d6f-8ffb-64429e62b520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0616-1609_lunar-Duel-noisy-LR0.001-GAMMA0.99\n",
            "Episode 1\tAction length: 93, Total reward: -712.89, Average reward: -712.89, Final reward: -100.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/frankchiang/local/anaconda3/envs/ml2023_hw12/lib/python3.7/site-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 2\tAction length: 59, Total reward: -568.59, Average reward: -640.74, Final reward: -100.00\n",
            "Episode 3\tAction length: 63, Total reward: -503.81, Average reward: -595.09, Final reward: -100.00\n",
            "Episode 4\tAction length: 78, Total reward: -724.44, Average reward: -627.43, Final reward: -100.00\n",
            "Episode 5\tAction length: 66, Total reward: -134.95, Average reward: -528.94, Final reward: -100.00\n",
            "Episode 6\tAction length: 74, Total reward: -743.17, Average reward: -564.64, Final reward: -100.00\n",
            "Episode 7\tAction length: 51, Total reward: -445.37, Average reward: -547.60, Final reward: -100.00\n",
            "Episode 8\tAction length: 78, Total reward: -710.11, Average reward: -567.92, Final reward: -100.00\n",
            "Episode 9\tAction length: 77, Total reward: -398.86, Average reward: -549.13, Final reward: -100.00\n",
            "Episode 100\tAction length: 158, Total reward: -155.87, Average reward: -170.76, Final reward: -100.00\n",
            "Episode 200\tAction length: 354, Total reward: -97.18, Average reward: -168.24, Final reward: -100.00\n",
            "Episode 236\tAction length: 603, Total reward: 167.97, Average reward: -168.19, Final reward: 100.00 <-- good\n",
            "Episode 236\t Avg test reward: -154.77 <-- best\n",
            "Episode 252\tAction length: 693, Total reward: 193.71, Average reward: -165.83, Final reward: 100.00 <-- good\n",
            "Episode 252\t Avg test reward: -120.22 <-- best\n",
            "Episode 258\tAction length: 287, Total reward: 209.00, Average reward: -164.52, Final reward: 100.00 <-- good\n",
            "Episode 258\t Avg test reward: -88.57 <-- best\n",
            "Episode 280\tAction length: 425, Total reward: 191.62, Average reward: -161.12, Final reward: 100.00 <-- good\n",
            "Episode 300\tAction length: 999, Total reward: -105.20, Average reward: -157.44, Final reward: -1.24\n",
            "Episode 304\tAction length: 390, Total reward: 212.57, Average reward: -156.21, Final reward: 100.00 <-- good\n",
            "Episode 304\t Avg test reward: 44.29 <-- best\n",
            "Episode 318\tAction length: 695, Total reward: 164.73, Average reward: -155.09, Final reward: 100.00 <-- good\n",
            "Episode 337\tAction length: 690, Total reward: 90.20, Average reward: -149.95, Final reward: 100.00 <-- good\n",
            "Episode 355\tAction length: 949, Total reward: 92.89, Average reward: -145.57, Final reward: 100.00 <-- good\n",
            "Episode 384\tAction length: 598, Total reward: 113.46, Average reward: -141.48, Final reward: 100.00 <-- good\n",
            "Episode 400\tAction length: 999, Total reward: -58.97, Average reward: -138.74, Final reward: -2.03\n",
            "Episode 419\tAction length: 493, Total reward: 138.05, Average reward: -136.08, Final reward: 100.00 <-- good\n",
            "Episode 463\tAction length: 831, Total reward: 130.22, Average reward: -131.34, Final reward: 100.00 <-- good\n",
            "Episode 472\tAction length: 308, Total reward: 192.22, Average reward: -130.37, Final reward: 100.00 <-- good\n",
            "Episode 500\tAction length: 999, Total reward: -26.80, Average reward: -128.46, Final reward: 3.12\n",
            "Episode 525\tAction length: 642, Total reward: 194.72, Average reward: -125.82, Final reward: 100.00 <-- good\n",
            "Episode 600\tAction length: 999, Total reward: -56.20, Average reward: -120.74, Final reward: 0.94\n",
            "Episode 700\tAction length: 112, Total reward: -183.39, Average reward: -116.93, Final reward: -100.00\n",
            "Episode 800\tAction length: 180, Total reward: -89.34, Average reward: -121.55, Final reward: -100.00\n",
            "Episode 900\tAction length: 999, Total reward: -51.10, Average reward: -125.01, Final reward: -1.81.\n",
            "Episode 1000\tAction length: 99, Total reward: -96.38, Average reward: -126.81, Final reward: -100.00\n",
            "Episode 1063\tAction length: 375, Total reward: 222.74, Average reward: -120.27, Final reward: 100.00 <-- good\n",
            "Episode 1100\tAction length: 105, Total reward: -175.80, Average reward: -123.53, Final reward: -100.00\n",
            "Episode 1154\tAction length: 354, Total reward: 113.72, Average reward: -123.24, Final reward: 100.00 <-- good\n",
            "Episode 1200\tAction length: 117, Total reward: -353.89, Average reward: -121.09, Final reward: -100.00\n",
            "Episode 1219\tAction length: 382, Total reward: 233.57, Average reward: -120.08, Final reward: 100.00 <-- good\n",
            "Episode 1297\tAction length: 375, Total reward: 148.32, Average reward: -121.41, Final reward: 100.00 <-- good\n",
            "Episode 1300\tAction length: 103, Total reward: -139.72, Average reward: -121.68, Final reward: -100.00\n",
            "Episode 1314\tAction length: 201, Total reward: 238.10, Average reward: -121.67, Final reward: 100.00 <-- good\n",
            "Episode 1328\tAction length: 264, Total reward: 238.50, Average reward: -122.45, Final reward: 100.00 <-- good\n",
            "Episode 1352\tAction length: 536, Total reward: 138.58, Average reward: -124.27, Final reward: 100.00 <-- good\n",
            "Episode 1358\tAction length: 306, Total reward: 192.66, Average reward: -124.51, Final reward: 100.00 <-- good\n",
            "Episode 1368\tAction length: 425, Total reward: 139.60, Average reward: -124.71, Final reward: 100.00 <-- good\n",
            "Episode 1400\tAction length: 90, Total reward: -156.82, Average reward: -127.45, Final reward: -100.00\n",
            "Episode 1422\tAction length: 258, Total reward: 235.48, Average reward: -128.41, Final reward: 100.00 <-- good\n",
            "Episode 1428\tAction length: 355, Total reward: 217.75, Average reward: -128.61, Final reward: 100.00 <-- good\n",
            "Episode 1435\tAction length: 313, Total reward: 209.36, Average reward: -128.64, Final reward: 100.00 <-- good\n",
            "Episode 1473\tAction length: 335, Total reward: 162.43, Average reward: -130.87, Final reward: 100.00 <-- good\n",
            "Episode 1476\tAction length: 414, Total reward: 199.00, Average reward: -130.58, Final reward: 100.00 <-- good\n",
            "Episode 1490\tAction length: 399, Total reward: 198.47, Average reward: -131.39, Final reward: 100.00 <-- good\n",
            "Episode 1500\tAction length: 893, Total reward: -186.05, Average reward: -132.06, Final reward: -100.00\n",
            "Episode 1504\tAction length: 254, Total reward: 167.57, Average reward: -132.06, Final reward: 100.00 <-- good\n",
            "Episode 1514\tAction length: 551, Total reward: 167.00, Average reward: -131.97, Final reward: 100.00 <-- good\n",
            "Episode 1517\tAction length: 630, Total reward: 96.88, Average reward: -131.82, Final reward: 100.00 <-- good\n",
            "Episode 1577\tAction length: 389, Total reward: 161.09, Average reward: -135.57, Final reward: 100.00 <-- good\n",
            "Episode 1578\tAction length: 249, Total reward: 138.22, Average reward: -135.39, Final reward: 100.00 <-- good\n",
            "Episode 1586\tAction length: 778, Total reward: 182.58, Average reward: -135.42, Final reward: 100.00 <-- good\n",
            "Episode 1600\tAction length: 442, Total reward: -179.93, Average reward: -136.74, Final reward: -100.00\n",
            "Episode 1624\tAction length: 530, Total reward: 112.70, Average reward: -138.76, Final reward: 100.00 <-- good\n",
            "Episode 1653\tAction length: 291, Total reward: 228.12, Average reward: -142.25, Final reward: 100.00 <-- good\n",
            "Episode 1665\tAction length: 295, Total reward: 252.14, Average reward: -142.77, Final reward: 100.00 <-- good\n",
            "Episode 1671\tAction length: 474, Total reward: 191.17, Average reward: -142.60, Final reward: 100.00 <-- good\n",
            "Episode 1700\tAction length: 205, Total reward: -153.59, Average reward: -143.69, Final reward: -100.00\n",
            "Episode 1728\tAction length: 328, Total reward: 233.63, Average reward: -143.85, Final reward: 100.00 <-- good\n",
            "Episode 1755\tAction length: 628, Total reward: 172.57, Average reward: -144.06, Final reward: 100.00 <-- good\n",
            "Episode 1779\tAction length: 651, Total reward: 171.13, Average reward: -143.06, Final reward: 100.00 <-- good\n",
            "Episode 1800\tAction length: 290, Total reward: -158.64, Average reward: -142.31, Final reward: -100.00\n",
            "Episode 1900\tAction length: 359, Total reward: -139.66, Average reward: -142.39, Final reward: -100.00\n",
            "Episode 1930\tAction length: 918, Total reward: 70.20, Average reward: -141.95, Final reward: 100.00 <-- good\n",
            "Episode 2000\tAction length: 999, Total reward: -86.61, Average reward: -143.17, Final reward: -4.10\n",
            "Episode 2087\tAction length: 717, Total reward: 145.07, Average reward: -146.83, Final reward: 100.00 <-- good\n",
            "Episode 2100\tAction length: 999, Total reward: -44.22, Average reward: -147.77, Final reward: 1.66\n",
            "Episode 2151\tAction length: 381, Total reward: 188.15, Average reward: -148.43, Final reward: 100.00 <-- good\n",
            "Episode 2200\tAction length: 999, Total reward: -160.64, Average reward: -149.27, Final reward: -1.80\n",
            "Episode 2204\tAction length: 678, Total reward: 103.57, Average reward: -149.11, Final reward: 100.00 <-- good\n",
            "Episode 2231\tAction length: 705, Total reward: 210.77, Average reward: -149.25, Final reward: 100.00 <-- good\n",
            "Episode 2260\tAction length: 402, Total reward: 215.36, Average reward: -148.07, Final reward: 100.00 <-- good\n",
            "Episode 2273\tAction length: 368, Total reward: 240.89, Average reward: -147.88, Final reward: 100.00 <-- good\n",
            "Episode 2286\tAction length: 766, Total reward: 249.86, Average reward: -146.88, Final reward: 100.00 <-- good\n",
            "Episode 2300\tAction length: 999, Total reward: -77.13, Average reward: -147.04, Final reward: 5.12\n",
            "Episode 2308\tAction length: 604, Total reward: 202.23, Average reward: -146.65, Final reward: 100.00 <-- good\n",
            "Episode 2311\tAction length: 810, Total reward: 169.70, Average reward: -146.35, Final reward: 100.00 <-- good\n",
            "Episode 2331\tAction length: 974, Total reward: 116.30, Average reward: -146.00, Final reward: 100.00 <-- good\n",
            "Episode 2333\tAction length: 978, Total reward: 70.25, Average reward: -145.84, Final reward: 100.00 <-- good\n",
            "Episode 2334\tAction length: 929, Total reward: 97.35, Average reward: -145.61, Final reward: 100.00 <-- good\n",
            "Episode 2336\tAction length: 631, Total reward: 191.53, Average reward: -145.34, Final reward: 100.00 <-- good\n",
            "Episode 2342\tAction length: 742, Total reward: 128.59, Average reward: -144.67, Final reward: 100.00 <-- good\n",
            "Episode 2366\tAction length: 697, Total reward: 147.28, Average reward: -144.35, Final reward: 100.00 <-- good\n",
            "Episode 2400\tAction length: 999, Total reward: 23.69, Average reward: -142.90, Final reward: 3.10\n",
            "Episode 2403\tAction length: 201, Total reward: 252.47, Average reward: -142.13, Final reward: 100.00 <-- good\n",
            "Episode 2405\tAction length: 459, Total reward: 258.08, Average reward: -141.81, Final reward: 100.00 <-- good\n",
            "Episode 2408\tAction length: 928, Total reward: 208.75, Average reward: -141.41, Final reward: 100.00 <-- good\n",
            "Episode 2417\tAction length: 616, Total reward: 233.96, Average reward: -141.13, Final reward: 100.00 <-- good\n",
            "Episode 2419\tAction length: 725, Total reward: 162.75, Average reward: -140.83, Final reward: 100.00 <-- good\n",
            "Episode 2423\tAction length: 564, Total reward: 128.75, Average reward: -140.71, Final reward: 100.00 <-- good\n",
            "Episode 2424\tAction length: 967, Total reward: 114.39, Average reward: -140.39, Final reward: 100.00 <-- good\n",
            "Episode 2427\tAction length: 877, Total reward: 108.33, Average reward: -140.11, Final reward: 100.00 <-- good\n",
            "Episode 2429\tAction length: 737, Total reward: 199.31, Average reward: -140.17, Final reward: 100.00 <-- good\n",
            "Episode 2451\tAction length: 464, Total reward: 206.39, Average reward: -138.95, Final reward: 100.00 <-- good\n",
            "Episode 2462\tAction length: 533, Total reward: 179.70, Average reward: -137.99, Final reward: 100.00 <-- good\n",
            "Episode 2464\tAction length: 895, Total reward: 134.43, Average reward: -137.63, Final reward: 100.00 <-- good\n",
            "Episode 2468\tAction length: 878, Total reward: 155.34, Average reward: -137.02, Final reward: 100.00 <-- good\n",
            "Episode 2469\tAction length: 715, Total reward: 141.23, Average reward: -136.71, Final reward: 100.00 <-- good\n",
            "Episode 2470\tAction length: 733, Total reward: 247.42, Average reward: -136.29, Final reward: 100.00 <-- good\n",
            "Episode 2473\tAction length: 358, Total reward: 240.53, Average reward: -136.14, Final reward: 100.00 <-- good\n",
            "Episode 2491\tAction length: 829, Total reward: 76.43, Average reward: -135.04, Final reward: 100.00 <-- good\n",
            "Episode 2493\tAction length: 673, Total reward: 122.39, Average reward: -134.56, Final reward: 100.00 <-- good\n",
            "Episode 2496\tAction length: 452, Total reward: 208.10, Average reward: -134.11, Final reward: 100.00 <-- good\n",
            "Episode 2500\tAction length: 999, Total reward: -54.16, Average reward: -134.00, Final reward: 1.75\n",
            "Episode 2501\tAction length: 338, Total reward: 146.57, Average reward: -133.73, Final reward: 100.00 <-- good\n",
            "Episode 2506\tAction length: 596, Total reward: 165.19, Average reward: -133.63, Final reward: 100.00 <-- good\n",
            "Episode 2519\tAction length: 466, Total reward: 158.41, Average reward: -133.43, Final reward: 100.00 <-- good\n",
            "Episode 2524\tAction length: 825, Total reward: 107.03, Average reward: -133.08, Final reward: 100.00 <-- good\n",
            "Episode 2527\tAction length: 366, Total reward: 178.03, Average reward: -132.63, Final reward: 100.00 <-- good\n",
            "Episode 2540\tAction length: 679, Total reward: 132.93, Average reward: -132.01, Final reward: 100.00 <-- good\n",
            "Episode 2541\tAction length: 330, Total reward: 202.42, Average reward: -131.60, Final reward: 100.00 <-- good\n",
            "Episode 2545\tAction length: 460, Total reward: 225.83, Average reward: -130.80, Final reward: 100.00 <-- good\n",
            "Episode 2547\tAction length: 211, Total reward: 252.26, Average reward: -130.35, Final reward: 100.00 <-- good\n",
            "Episode 2548\tAction length: 387, Total reward: 157.88, Average reward: -130.09, Final reward: 100.00 <-- good\n",
            "Episode 2552\tAction length: 646, Total reward: 185.42, Average reward: -129.70, Final reward: 100.00 <-- good\n",
            "Episode 2552\t Avg test reward: 162.24 <-- best\n",
            "Episode 2556\tAction length: 614, Total reward: 173.88, Average reward: -129.19, Final reward: 100.00 <-- good\n",
            "Episode 2557\tAction length: 986, Total reward: 127.06, Average reward: -128.83, Final reward: 100.00 <-- success\n",
            "Episode 2563\tAction length: 429, Total reward: 230.16, Average reward: -128.15, Final reward: 100.00 <-- good\n",
            "Episode 2564\tAction length: 534, Total reward: 173.59, Average reward: -127.85, Final reward: 100.00 <-- good\n",
            "Episode 2568\tAction length: 353, Total reward: 151.76, Average reward: -127.11, Final reward: 100.00 <-- success\n",
            "Episode 2584\tAction length: 888, Total reward: 153.31, Average reward: -126.60, Final reward: 100.00 <-- success\n",
            "Episode 2585\tAction length: 410, Total reward: 207.43, Average reward: -126.23, Final reward: 100.00 <-- good\n",
            "Episode 2586\tAction length: 269, Total reward: 225.37, Average reward: -126.19, Final reward: 100.00 <-- good\n",
            "Episode 2587\tAction length: 341, Total reward: 208.10, Average reward: -125.83, Final reward: 100.00 <-- good\n",
            "Episode 2589\tAction length: 639, Total reward: 154.15, Average reward: -125.43, Final reward: 100.00 <-- success\n",
            "Episode 2590\tAction length: 285, Total reward: 250.01, Average reward: -125.07, Final reward: 100.00 <-- good\n",
            "Episode 2600\tAction length: 999, Total reward: -172.31, Average reward: -124.05, Final reward: -0.41\n",
            "Episode 2606\tAction length: 333, Total reward: 130.52, Average reward: -123.50, Final reward: 100.00 <-- success\n",
            "Episode 2608\tAction length: 543, Total reward: 174.46, Average reward: -123.02, Final reward: 100.00 <-- good\n",
            "Episode 2611\tAction length: 243, Total reward: 233.02, Average reward: -122.49, Final reward: 100.00 <-- good\n",
            "Episode 2614\tAction length: 486, Total reward: 230.07, Average reward: -122.08, Final reward: 100.00 <-- good\n",
            "Episode 2615\tAction length: 694, Total reward: 159.79, Average reward: -121.73, Final reward: 100.00 <-- success\n",
            "Episode 2618\tAction length: 740, Total reward: 173.48, Average reward: -121.08, Final reward: 100.00 <-- good\n",
            "Episode 2626\tAction length: 439, Total reward: 169.38, Average reward: -120.89, Final reward: 100.00 <-- good\n",
            "Episode 2645\tAction length: 982, Total reward: 110.91, Average reward: -119.17, Final reward: 100.00 <-- success\n",
            "Episode 2659\tAction length: 940, Total reward: 127.82, Average reward: -118.39, Final reward: 100.00 <-- success\n",
            "Episode 2664\tAction length: 512, Total reward: 198.67, Average reward: -117.47, Final reward: 100.00 <-- good\n",
            "Episode 2669\tAction length: 236, Total reward: 217.53, Average reward: -117.56, Final reward: 100.00 <-- good\n",
            "Episode 2678\tAction length: 824, Total reward: 238.83, Average reward: -117.29, Final reward: 100.00 <-- good\n",
            "Episode 2683\tAction length: 460, Total reward: 200.23, Average reward: -116.93, Final reward: 100.00 <-- good\n",
            "Episode 2694\tAction length: 743, Total reward: 183.62, Average reward: -116.04, Final reward: 100.00 <-- good\n",
            "Episode 2698\tAction length: 815, Total reward: 203.13, Average reward: -115.74, Final reward: 100.00 <-- good\n",
            "Episode 2700\tAction length: 508, Total reward: 180.55, Average reward: -115.28, Final reward: 100.00\n",
            "Episode 2700\tAction length: 508, Total reward: 180.55, Average reward: -115.28, Final reward: 100.00 <-- good\n",
            "Episode 2702\tAction length: 269, Total reward: 262.22, Average reward: -114.71, Final reward: 100.00 <-- good\n",
            "Episode 2720\tAction length: 582, Total reward: 205.34, Average reward: -114.71, Final reward: 100.00 <-- good\n",
            "Episode 2722\tAction length: 660, Total reward: 200.73, Average reward: -114.59, Final reward: 100.00 <-- good\n",
            "Episode 2757\tAction length: 407, Total reward: 237.85, Average reward: -115.03, Final reward: 100.00 <-- good\n",
            "Episode 2800\tAction length: 158, Total reward: -147.21, Average reward: -115.33, Final reward: -100.00\n",
            "Episode 2802\tAction length: 512, Total reward: 148.36, Average reward: -115.09, Final reward: 100.00 <-- success\n",
            "Episode 2805\tAction length: 497, Total reward: 161.97, Average reward: -114.69, Final reward: 100.00 <-- success\n",
            "Episode 2806\tAction length: 477, Total reward: 223.85, Average reward: -114.31, Final reward: 100.00 <-- good\n",
            "Episode 2812\tAction length: 509, Total reward: 255.92, Average reward: -113.95, Final reward: 100.00 <-- good\n",
            "Episode 2813\tAction length: 301, Total reward: 254.82, Average reward: -113.46, Final reward: 100.00 <-- good\n",
            "Episode 2815\tAction length: 410, Total reward: 180.23, Average reward: -112.96, Final reward: 100.00 <-- good\n",
            "Episode 2820\tAction length: 461, Total reward: 190.87, Average reward: -112.24, Final reward: 100.00 <-- good\n",
            "Episode 2826\tAction length: 748, Total reward: 137.26, Average reward: -112.18, Final reward: 100.00 <-- success\n",
            "Episode 2831\tAction length: 328, Total reward: 229.38, Average reward: -112.11, Final reward: 100.00 <-- good\n",
            "Episode 2837\tAction length: 596, Total reward: 211.91, Average reward: -111.71, Final reward: 100.00 <-- good\n",
            "Episode 2838\tAction length: 398, Total reward: 259.05, Average reward: -111.27, Final reward: 100.00 <-- good\n",
            "Episode 2844\tAction length: 615, Total reward: 156.70, Average reward: -111.06, Final reward: 100.00 <-- success\n",
            "Episode 2845\tAction length: 650, Total reward: 256.07, Average reward: -110.69, Final reward: 100.00 <-- good\n",
            "Episode 2846\tAction length: 621, Total reward: 118.80, Average reward: -110.40, Final reward: 100.00 <-- success\n",
            "Episode 2847\tAction length: 600, Total reward: 202.19, Average reward: -110.09, Final reward: 100.00 <-- good\n",
            "Episode 2858\tAction length: 507, Total reward: 147.38, Average reward: -109.15, Final reward: 100.00 <-- success\n",
            "Episode 2859\tAction length: 237, Total reward: 210.64, Average reward: -108.76, Final reward: 100.00 <-- good\n",
            "Episode 2860\tAction length: 914, Total reward: 86.89, Average reward: -108.55, Final reward: 100.00 <-- success\n",
            "Episode 2863\tAction length: 478, Total reward: 235.03, Average reward: -108.02, Final reward: 100.00 <-- good\n",
            "Episode 2866\tAction length: 329, Total reward: 240.42, Average reward: -107.68, Final reward: 100.00 <-- good\n",
            "Episode 2867\tAction length: 499, Total reward: 192.27, Average reward: -107.26, Final reward: 100.00 <-- good\n",
            "Episode 2870\tAction length: 408, Total reward: 249.02, Average reward: -106.69, Final reward: 100.00 <-- good\n",
            "Episode 2875\tAction length: 317, Total reward: 227.33, Average reward: -106.47, Final reward: 100.00 <-- good\n",
            "Episode 2885\tAction length: 575, Total reward: 182.79, Average reward: -105.82, Final reward: 100.00 <-- good\n",
            "Episode 2887\tAction length: 372, Total reward: 195.27, Average reward: -105.59, Final reward: 100.00 <-- good\n",
            "Episode 2900\tAction length: 999, Total reward: -37.15, Average reward: -105.70, Final reward: 0.08\n",
            "Episode 2903\tAction length: 585, Total reward: 168.12, Average reward: -105.58, Final reward: 100.00 <-- good\n",
            "Episode 2906\tAction length: 232, Total reward: 241.90, Average reward: -105.15, Final reward: 100.00 <-- good\n",
            "Episode 2910\tAction length: 330, Total reward: 247.68, Average reward: -105.10, Final reward: 100.00 <-- good\n",
            "Episode 2916\tAction length: 914, Total reward: 125.11, Average reward: -104.84, Final reward: 100.00 <-- success\n",
            "Episode 2927\tAction length: 267, Total reward: 203.59, Average reward: -104.10, Final reward: 100.00 <-- good\n",
            "Episode 2937\tAction length: 790, Total reward: 145.22, Average reward: -103.58, Final reward: 100.00 <-- success\n",
            "Episode 2943\tAction length: 392, Total reward: 175.88, Average reward: -102.85, Final reward: 100.00 <-- good\n",
            "Episode 2955\tAction length: 402, Total reward: 155.65, Average reward: -101.76, Final reward: 100.00 <-- success\n",
            "Episode 2961\tAction length: 747, Total reward: 171.91, Average reward: -101.31, Final reward: 100.00 <-- good\n",
            "Episode 2973\tAction length: 913, Total reward: 142.50, Average reward: -100.22, Final reward: 100.00 <-- success\n",
            "Episode 2983\tAction length: 335, Total reward: 239.54, Average reward: -99.81, Final reward: 100.00 <-- good\n",
            "Episode 2990\tAction length: 697, Total reward: 123.16, Average reward: -99.46, Final reward: 100.00 <-- success\n",
            "Episode 3000\tAction length: 133, Total reward: -197.30, Average reward: -98.89, Final reward: -100.00\n",
            "Episode 3013\tAction length: 752, Total reward: 171.10, Average reward: -98.17, Final reward: 100.00 <-- good\n",
            "Episode 3032\tAction length: 305, Total reward: 231.34, Average reward: -95.97, Final reward: 100.00 <-- good\n",
            "Episode 3050\tAction length: 547, Total reward: 200.77, Average reward: -93.28, Final reward: 100.00 <-- good\n",
            "Episode 3053\tAction length: 461, Total reward: 211.31, Average reward: -92.74, Final reward: 100.00 <-- good\n",
            "Episode 3062\tAction length: 721, Total reward: 134.81, Average reward: -91.21, Final reward: 100.00 <-- success\n",
            "Episode 3063\tAction length: 464, Total reward: 165.90, Average reward: -90.86, Final reward: 100.00 <-- good\n",
            "Episode 3071\tAction length: 827, Total reward: 102.13, Average reward: -90.21, Final reward: 100.00 <-- success\n",
            "Episode 3072\tAction length: 396, Total reward: 197.73, Average reward: -89.81, Final reward: 100.00 <-- good\n",
            "Episode 3073\tAction length: 412, Total reward: 207.37, Average reward: -89.39, Final reward: 100.00 <-- good\n",
            "Episode 3074\tAction length: 438, Total reward: 182.12, Average reward: -88.98, Final reward: 100.00 <-- good\n",
            "Episode 3077\tAction length: 641, Total reward: 175.20, Average reward: -88.30, Final reward: 100.00 <-- good\n",
            "Episode 3080\tAction length: 293, Total reward: 220.46, Average reward: -87.64, Final reward: 100.00 <-- good\n",
            "Episode 3082\tAction length: 921, Total reward: 116.16, Average reward: -87.38, Final reward: 100.00 <-- success\n",
            "Episode 3090\tAction length: 331, Total reward: 245.74, Average reward: -86.01, Final reward: 100.00 <-- good\n",
            "Episode 3099\tAction length: 730, Total reward: 174.25, Average reward: -84.60, Final reward: 100.00 <-- good\n",
            "Episode 3100\tAction length: 354, Total reward: -22.26, Average reward: -84.58, Final reward: -100.00\n",
            "Episode 3103\tAction length: 607, Total reward: 183.97, Average reward: -83.83, Final reward: 100.00 <-- good\n",
            "Episode 3120\tAction length: 301, Total reward: 258.34, Average reward: -80.88, Final reward: 100.00 <-- good\n",
            "Episode 3125\tAction length: 657, Total reward: 207.10, Average reward: -80.44, Final reward: 100.00 <-- good\n",
            "Episode 3134\tAction length: 583, Total reward: 198.11, Average reward: -79.46, Final reward: 100.00 <-- good\n",
            "Episode 3151\tAction length: 426, Total reward: 136.76, Average reward: -77.91, Final reward: 100.00 <-- success\n",
            "Episode 3158\tAction length: 593, Total reward: 141.25, Average reward: -76.55, Final reward: 100.00 <-- success\n",
            "Episode 3168\tAction length: 299, Total reward: 190.25, Average reward: -75.23, Final reward: 100.00 <-- good\n",
            "Episode 3175\tAction length: 350, Total reward: 234.55, Average reward: -74.23, Final reward: 100.00 <-- good\n",
            "Episode 3186\tAction length: 646, Total reward: 215.83, Average reward: -72.98, Final reward: 100.00 <-- good\n",
            "Episode 3200\tAction length: 999, Total reward: -12.01, Average reward: -71.43, Final reward: 0.51\n",
            "Episode 3211\tAction length: 598, Total reward: 143.94, Average reward: -70.50, Final reward: 100.00 <-- success\n",
            "Episode 3286\tAction length: 515, Total reward: 221.76, Average reward: -67.30, Final reward: 100.00 <-- good\n",
            "Episode 3300\tAction length: 302, Total reward: -93.62, Average reward: -66.59, Final reward: -100.00\n",
            "Episode 3326\tAction length: 712, Total reward: 144.43, Average reward: -65.31, Final reward: 100.00 <-- success\n",
            "Episode 3353\tAction length: 746, Total reward: 115.69, Average reward: -65.10, Final reward: 100.00 <-- success\n",
            "Episode 3389\tAction length: 629, Total reward: 190.62, Average reward: -62.83, Final reward: 100.00 <-- good\n",
            "Episode 3400\tAction length: 999, Total reward: -140.72, Average reward: -62.39, Final reward: 2.53\n",
            "Episode 3433\tAction length: 233, Total reward: 264.97, Average reward: -63.74, Final reward: 100.00 <-- good\n",
            "Episode 3439\tAction length: 890, Total reward: 114.39, Average reward: -63.35, Final reward: 100.00 <-- success\n",
            "Episode 3451\tAction length: 852, Total reward: 105.72, Average reward: -63.29, Final reward: 100.00 <-- success\n",
            "Episode 3465\tAction length: 725, Total reward: 132.83, Average reward: -63.37, Final reward: 100.00 <-- success\n",
            "Episode 3500\tAction length: 999, Total reward: -25.90, Average reward: -64.09, Final reward: 2.29\n",
            "Episode 3583\tAction length: 882, Total reward: 123.38, Average reward: -68.54, Final reward: 100.00 <-- success\n",
            "Episode 3598\tAction length: 310, Total reward: 229.54, Average reward: -70.02, Final reward: 100.00 <-- good\n",
            "Episode 3600\tAction length: 877, Total reward: -190.08, Average reward: -70.13, Final reward: -100.00\n",
            "Episode 3601\tAction length: 877, Total reward: 103.11, Average reward: -69.97, Final reward: 100.00 <-- success\n",
            "Episode 3700\tAction length: 999, Total reward: -97.50, Average reward: -73.89, Final reward: 2.67.\n",
            "Episode 3712\tAction length: 667, Total reward: 160.49, Average reward: -73.42, Final reward: 100.00 <-- success\n",
            "Episode 3730\tAction length: 910, Total reward: 48.41, Average reward: -72.50, Final reward: 100.00 <-- success\n",
            "Episode 3800\tAction length: 999, Total reward: -140.78, Average reward: -71.74, Final reward: -3.58\n",
            "Episode 3808\tAction length: 862, Total reward: 65.75, Average reward: -72.09, Final reward: 100.00 <-- success\n",
            "Episode 3810\tAction length: 986, Total reward: 94.92, Average reward: -71.74, Final reward: 100.00 <-- success\n",
            "Episode 3831\tAction length: 639, Total reward: 156.79, Average reward: -72.64, Final reward: 100.00 <-- success\n",
            "Episode 3847\tAction length: 749, Total reward: 105.57, Average reward: -73.85, Final reward: 100.00 <-- success\n",
            "Episode 3865\tAction length: 408, Total reward: 191.42, Average reward: -74.98, Final reward: 100.00 <-- good\n",
            "Episode 3895\tAction length: 786, Total reward: 85.55, Average reward: -74.80, Final reward: 100.00 <-- success\n",
            "Episode 3900\tAction length: 999, Total reward: -19.04, Average reward: -75.21, Final reward: -2.70\n",
            "Episode 3960\tAction length: 481, Total reward: 185.61, Average reward: -75.00, Final reward: 100.00 <-- good\n",
            "Episode 3962\tAction length: 678, Total reward: 181.60, Average reward: -75.09, Final reward: 100.00 <-- good\n",
            "Episode 4000\tAction length: 999, Total reward: -133.32, Average reward: -75.05, Final reward: -1.61\n",
            "avgTotal: -111.0, avgFinalReward: -48.7, bestReward: 162.24082068577346\n",
            "\n",
            "Total time is 6649.281968593597 sec\n",
            "Best Reward is 162.24082068577346\n"
          ]
        }
      ],
      "source": [
        "work_name = \"lunar\"\n",
        "if DUELING: work_name += \"-Duel\"\n",
        "if PARAM_NOISE: work_name += \"-noisy\"\n",
        "work_name += \"-LR\" + str(LR) + \"-GAMMA\" + str(GAMMA)\n",
        "\n",
        "start_run_time = datetime.now().strftime(\"%m%d-%H%M\")\n",
        "work_dir = start_run_time + \"_\" + work_name\n",
        "print(work_dir)\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "agent = Agent(state_size=8, action_size=4)\n",
        "agent.qnetwork_local.train()  # 訓練前，先確保 network 處在 training 模式\n",
        "total_rewards, final_rewards, best_reward = train(agent, n_episode=EPOCH, max_t=9999, work_dir=work_dir, save_every=50)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"\\nTotal time is {end-start} sec\")\n",
        "print(f\"Best Reward is {best_reward}\")\n",
        "\n",
        "## Write training process\n",
        "with open(f'{work_dir}/rewards.txt', 'a') as fp:\n",
        "    for i in range(EPOCH):\n",
        "        fp.write(\"%s \" % total_rewards[i])\n",
        "    fp.write(\"\\n\")\n",
        "with open(f'{work_dir}/costs.txt', 'a') as fp:\n",
        "    for i in range(EPOCH):\n",
        "        fp.write(\"%s \" % final_rewards[i])\n",
        "    fp.write(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_tuFYhKVK"
      },
      "source": [
        "### Training Result\n",
        "During the training process, we recorded `avg_total_reward`, which represents the average total reward of episodes before updating the policy network.\n",
        "\n",
        "Theoretically, if the agent becomes better, the `avg_total_reward` will increase.\n",
        "The visualization of the training process is shown below:  \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5jj4dThz0Y"
      },
      "source": [
        "In addition, `avg_final_reward` represents average final rewards of episodes. To be specific, final rewards is the last reward received in one episode, indicating whether the craft lands successfully or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "resol=6\n",
        "colors = ['blue', 'red', 'orange', 'green', 'purple']\n",
        "fig, axarr = plt.subplots(2,2)\n",
        "plt.subplots_adjust(wspace=0.4,\n",
        "                    hspace=0.4)\n",
        "with open(f'{work_dir}/costs.txt', 'r') as fp: # costs\n",
        "    lines=fp.readlines()\n",
        "    lines=[list(map(float,line.split())) for line in lines]\n",
        "    avgs=[]\n",
        "    for i in range(len(lines)):\n",
        "        EPOCH = len(lines[i])\n",
        "        avg=[]\n",
        "        for j in range(len(lines[i])):\n",
        "            avg.append(sum(lines[i][0:(j+1)]) / (j+1))\n",
        "        avgs.append(avg)\n",
        "    for i in range(len(lines)):\n",
        "        axarr[0][0].plot(range(math.ceil(EPOCH/resol)), lines[i][0::resol], color=colors[i])\n",
        "        axarr[0][0].set_title('Each Step Reward', fontstyle='italic', fontsize='medium')\n",
        "        axarr[0][1].plot(range(EPOCH), avgs[i], color=colors[i])\n",
        "        axarr[0][1].set_title('Avg Reward', fontstyle='italic', fontsize='medium')\n",
        "fp.close()\n",
        "with open(f'{work_dir}/rewards.txt', 'r') as fp2: # rewards\n",
        "    lines=fp2.readlines()\n",
        "    lines=[list(map(float,line.split())) for line in lines]\n",
        "    avgs=[]\n",
        "    for i in range(len(lines)):\n",
        "        EPOCH = len(lines[i])\n",
        "        avg=[]\n",
        "        for j in range(len(lines[i])):\n",
        "            avg.append(sum(lines[i][0:(j+1)]) / (j+1))\n",
        "        avgs.append(avg)\n",
        "    for i in range(len(lines)):\n",
        "        axarr[1][0].plot(range(math.ceil(EPOCH/resol)), lines[i][0::resol], color=colors[i])\n",
        "        axarr[1][0].set_title('Each Step Cost', fontstyle='italic', fontsize='medium')\n",
        "        axarr[1][1].plot(range(EPOCH), avgs[i], color=colors[i])\n",
        "        axarr[1][1].set_title('Avg Reward', fontstyle='italic', fontsize='medium')\n",
        "fp2.close()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HaGRVEYGQS"
      },
      "source": [
        "## Testing\n",
        "The testing result will be the average reward of 5 testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "5yFuUKKRYH73",
        "outputId": "01c686c0-3b85-46af-c96e-e0be4a58e9c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170.67359761626523\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_dir = \"./{}/best/\".format(work_dir)\n",
        "print(f\"best_dir: {best_dir}\")\n",
        "agent.load(best_dir+'Agent_Dict.ckpt')\n",
        "\n",
        "fix(env, seed)\n",
        "agent.qnetwork_local.eval()  # set the network into evaluation mode\n",
        "agent.qnetwork_target.eval()  # set the network into evaluation mode\n",
        "NUM_OF_TEST = 5 # Do not revise this !!!\n",
        "test_total_reward = []\n",
        "action_list = []\n",
        "for i in range(NUM_OF_TEST):\n",
        "  actions = []\n",
        "  state = env.reset()\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "  total_reward = 0\n",
        "  done = False\n",
        "  while not done:\n",
        "    action = agent.sample_action(state)\n",
        "    actions.append(action)\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True) \n",
        "  print(total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "  action_list.append(actions) # save the result of testing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aex7mcKr0J01",
        "outputId": "6e5aff83-5443-4e4c-8e8f-3a288c35cf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136.9959313438328\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(test_total_reward))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "leyebGYRpqsF"
      },
      "source": [
        "Action list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGAH4YWDpp4u",
        "outputId": "0a72e940-9393-4475-ea0e-1f3f816daec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action list looks like  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 3, 3, 3, 3, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 3, 3, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 3, 3, 3, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 3, 3, 3, 3, 3, 3, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 3, 3, 2, 2, 2, 3, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 3, 3, 3, 3, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 3, 3, 3, 3, 2, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
            "Action list's shape looks like  (5,)\n",
            "Action shape looks like  (955,)\n",
            "Action shape looks like  (660,)\n",
            "Action shape looks like  (494,)\n",
            "Action shape looks like  (137,)\n",
            "Action shape looks like  (522,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/frankchiang/local/anaconda3/envs/ml2023_hw12/lib/python3.7/site-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        }
      ],
      "source": [
        "print(\"Action list looks like \", action_list)\n",
        "print(\"Action list's shape looks like \", np.shape(action_list))\n",
        "\n",
        "for actions in action_list:\n",
        "    print(\"Action shape looks like \", np.shape(actions))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fNkmwucrHMen"
      },
      "source": [
        "Analysis of actions taken by agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHdAItjj1nxw",
        "outputId": "7b7010f3-fb1a-4d6f-8012-be5aa98794a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 940, 2: 1341, 1: 276, 3: 211}\n"
          ]
        }
      ],
      "source": [
        "distribution = {}\n",
        "for actions in action_list:\n",
        "  for action in actions:\n",
        "    if action not in distribution.keys():\n",
        "      distribution[action] = 1\n",
        "    else:\n",
        "      distribution[action] += 1\n",
        "print(distribution)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ricE0schY75M"
      },
      "source": [
        "Saving the result of Model Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZsMkGmIY42b",
        "outputId": "e9cee503-177a-462e-9298-5e5752b3e451"
      },
      "outputs": [],
      "source": [
        "# PATH = \"Action_List.npy\" # Can be modified into the name or path you want\n",
        "# np.save(PATH ,np.array(action_list)) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "asK7WfbkaLjt"
      },
      "source": [
        "### This is the file you need to submit !!!\n",
        "Download the testing result to your device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c-CqyhHzaWAL",
        "outputId": "d492cd1f-d843-4eb8-9a4a-b3bd6eae04d9"
      },
      "outputs": [],
      "source": [
        "PATH=best_dir+\"Action_List-test.npy\"\n",
        "# from google.colab import files\n",
        "# files.download(PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "seT4NUmWmAZ1"
      },
      "source": [
        "# Server \n",
        "The code below simulate the environment on the judge server. Can be used for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "U69c-YTxaw6b",
        "outputId": "f32f26a4-4d97-44b7-c2e9-1f69d87afb2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your reward is : 85.80\n",
            "Your reward is : 194.13\n",
            "Your reward is : 249.49\n",
            "Your reward is : -15.11\n",
            "Your reward is : 170.67\n"
          ]
        }
      ],
      "source": [
        "# PATH=best_dir+\"Action_List-test.npy\"\n",
        "action_list = np.load(PATH,allow_pickle=True) # The action list you upload\n",
        "seed = 2023 # Do not revise this\n",
        "fix(env, seed)\n",
        "\n",
        "agent.qnetwork_local.eval()  # set network to evaluation mode\n",
        "agent.qnetwork_target.eval()  # set network to evaluation mode\n",
        "\n",
        "test_total_reward = []\n",
        "if len(action_list) != 5:\n",
        "  print(\"Wrong format of file !!!\")\n",
        "  exit(0)\n",
        "for i, actions in enumerate(action_list):\n",
        "  state = env.reset()\n",
        "  #img = plt.imshow(env.render(mode='rgb_array'))\n",
        "  img_list = []\n",
        "  total_reward = 0\n",
        "  done = False\n",
        "  for action in actions:\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      total_reward += reward\n",
        "      img_list.append(Image.fromarray(env.render(mode='rgb_array'), 'RGB'))\n",
        "      if done:\n",
        "        break\n",
        "  gif_pth = best_dir + f\"layout-{i}.gif\"\n",
        "  imageio.mimsave(gif_pth, img_list, 'GIF', duration=1000)\n",
        "  img_list[0].save(gif_pth, save_all=True, append_images=img_list)\n",
        "  print(f\"Your reward is : %.2f\"%total_reward)\n",
        "  test_total_reward.append(total_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./0616-0220_lunar-Duel-noisy/best/\n"
          ]
        }
      ],
      "source": [
        "print(best_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjFBWwQP1hVe"
      },
      "source": [
        "# Your score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpJpZz3Wbm0X",
        "outputId": "08adba66-0ac6-4ba1-baf0-92ef5cbcdab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your final reward is : 136.99\n"
          ]
        }
      ],
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBtYXG2eaqf"
      },
      "source": [
        "## Reference\n",
        "\n",
        "Below are some useful tips for you to get high score.\n",
        "\n",
        "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
        "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
        "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "194b9ffbe5c8431ba02221e5f8f1e315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86cc078ee82412393be06fbb41dc603",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6af646edfbed423a893eb4ff5a80dc65",
            "value": 100
          }
        },
        "5805cbaeef104932bbc2886796b99a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b62bd445394f90914856c4e6ffad8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af646edfbed423a893eb4ff5a80dc65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76be8412fdd94bb99c9b071764057b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a75e87122a4c4b2fa75a69b27b0f9111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff52d7994d7848429da4dc9078d2f228",
              "IPY_MODEL_194b9ffbe5c8431ba02221e5f8f1e315",
              "IPY_MODEL_d961617cc2924a70ae866bf25c1643bb"
            ],
            "layout": "IPY_MODEL_66b62bd445394f90914856c4e6ffad8a"
          }
        },
        "a86cc078ee82412393be06fbb41dc603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad74a83a0e534484a27a1ff7b981c62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf39b080df3c4a9c9136740f657b0f79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d961617cc2924a70ae866bf25c1643bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5805cbaeef104932bbc2886796b99a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_76be8412fdd94bb99c9b071764057b9b",
            "value": " 100/100 [01:40&lt;00:00,  2.27s/it]"
          }
        },
        "ff52d7994d7848429da4dc9078d2f228": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf39b080df3c4a9c9136740f657b0f79",
            "placeholder": "​",
            "style": "IPY_MODEL_ad74a83a0e534484a27a1ff7b981c62a",
            "value": "Total: -179.2, Final: -100.0: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
